% !Mode:: "TeX:UTF-8"
\chapter{backend 2}
\begin{mdframed}
\textbf{main target}
\begin{enumerate}[labelindent=0em,leftmargin=1.5em]
\item Understand Sliding Window optimization.
\item Understand Pose Graph optimization.
\item Understands the optimization with tight coupling of the IMU.
\item Master the g2o Pose Graph and the IMU tightly coupled through experiments.
\end{enumerate}
\end{mdframed}

In the last lecture, we focused on the optimization of BA-based graphs. BA accurately optimizes the position and feature point of each camera. However, in larger scenes, the existence of a large number of feature points will seriously reduce the computational efficiency, resulting in an increasing amount of computation so that it cannot be real-time. The first part of this lecture introduces a simplified BA: pose diagram.

When the IMU sensor is carried on the robot, we can also calculate the relative motion between the image frames through the IMU. Similarly, the measurement data of the IMU can also be used as an optimization observation and placed in the optimization of the graph. The second part of this talk will introduce the mainstream optimization method in VIO: IMU tight coupling. This requires the reader to be proficient in the previously proposed graph optimization method.

\newpage
\section{Sliding window filtering and optimization}
\subsection{BA structure in the actual environment}
The map optimization with camera pose and spatial points is called BA, which can effectively solve large-scale positioning and mapping problems. This is very useful in the SfM problem, but in the SLAM process, we often need to control the size of the BA and keep the calculations real-time. If the computing power is infinite, then it's a good idea to calculate the entire BA all the time - but that doesn't fit the reality. The reality is that we must limit the computation time of the backend, such as no more than 20 iterations, no more than 0.5 seconds, and so on. An algorithm like SfM that uses a week to rebuild a city map is not necessarily effective in SLAM.

There are many ways to control the size of the calculation, such as extracting a part of the continuous video as \textbf{keyframe}\textsuperscript{\cite{Leutenegger2015}}, constructing only the BA between the key frame and the landmark point, so the non-key frame only Used for positioning and does not contribute to the construction. Even so, as time goes by, the number of key frames will increase and the map size will continue to grow. With batch optimization methods like BA, the computational efficiency will (worryly) continue to drop. In order to avoid this situation, we need to use some means to control the size of the back-end BA. These means can be theoretical or engineering.

For example, the easiest way to control the size of a BA is to keep only the nearest $N$ keyframes from the current moment and remove the earlier keyframes. Thus, our BA will be fixed in a time window, and the one leaving the window will be discarded. This method is called the sliding window method \textsuperscript{\cite{Sibley2008}}. Of course, there are some changes to the specific method of taking this $N$ keyframe. For example, it may not be necessary to take the most recent time, but according to certain principles, the keyframes that are close in time and spatially expandable can be taken. To ensure that the structure of the BA does not shrink into a group even when the camera is stopped (this easily leads to some bad degradation). If we consider the structure of the frame and frame deeper, we can also define a structure called "Covisibility graph" like ORB-SLAM2\textsuperscript{\cite{Mur-Artal2015}} ( See \autoref{fig:cov-graph}). The so-called common view refers to those "keyframes that are observed together with the current camera." Therefore, in BA optimization, we optimize some key frames and landmarks in the common view according to certain principles, for example. The key frame with more than 20 common road signs with the current frame remains unchanged for the other. When the common view relationship can be correctly constructed, the optimization based on the common view will remain optimal for a longer period of time.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{backend2/cov-graph.pdf}
\caption{Straight view of sliding window and common view}
\label{fig:cov-graph}
\end{figure}

Sliding windows, common views, and, in general, are some of the engineering compromises we have for real-time computing. But in theory, they also introduce a new problem: we just talked about "discarding" the sliding window, or "fixing" the variables outside the common view. What is this "discard" and "fixed"? ? "Fixed" seems easy to understand, we only need to keep the keyframe estimates outside the common view unchanged. But "discarding" means completely discarding, that is, the variables outside the window have no effect on the variables in the window at all, or the data outside the window \textbf{should} have some influence, but actually we ignore it? If there is an impact, what should this impact look like? It is not obvious enough, can you ignore it?

Next we will talk about these issues. How should they be handled theoretically, and whether they can be simplified in engineering.

\subsection{Sliding window method}
Now consider a sliding window. Suppose there are $N$ keyframes in this window. Their poses are expressed as: $$\bm{x}_1, \ldots, \bm{x}_N,$$ We assume that they are in vector space, ie use Li Algebraic expression, then, what can we talk about about these keyframes?

Obviously we care about where these keyframes are located and how they are uncertain, which corresponds to their mean covariance under Gaussian distribution assumptions. If these keyframes also correspond to a partial map, we can also ask what the mean and variance of the entire local system should be. There are also $M$ landmarks in this sliding window: $\bm{y}_1, \ldots, \bm{y}_N$, which form a partial map with $N$ keyframes. Obviously we can use the Bundle Adjustment method introduced in the previous section to deal with this sliding window, including building a graph optimization model, constructing a whole Hessian matrix, and then marginalizing all landmark points to speed up the solution. When marginalizing, we consider the pose of the keyframe, namely $$[\bm{x}_1, \ldots, \bm{x}_N]^\mathrm{T} \sim N([\boldsymbol{\mu }_1, \ldots, \boldsymbol{\mu}_N]^\mathrm{T}, \boldsymbol{\Sigma}).$$ where $\boldsymbol{\mu}_k$ is the $k$ keyframe The pose average, $\boldsymbol{\ Sigma}$ is the covariance matrix of all keyframes, then obviously, the mean part is the result after the BA iteration, and $\boldsymbol{\ Sigma}$ is the $\ for the entire BA. The result of the marginalization of the bm{H}$ matrix, the matrix $\bm{S}$ mentioned in the previous lecture. We believe that readers are already familiar with this process.

In the sliding window, our other question is, how do these state variables change when the window structure changes? This matter can be divided into two parts:
\begin{enumerate}
\item We need to add a keyframe to the window and the landmark points it observes.
\item We need to delete an old keyframe in the window, and we may also delete the landmark points it observes.
\end{enumerate}

At this time, the difference between the sliding window method and the traditional BA is revealed. Obviously, if it is processed according to the traditional BA, then this only corresponds to two BAs of different structures, and there is no difference in the solution. But if you are sliding the window, we will discuss these specific details.

\subsubsection{Add a keyframe and landmarks}
Considering that at the last moment, the sliding window has created $N$ keyframes, we also know that they obey a Gaussian distribution whose mean and variance are as described above. At this point, a new keyframe $\bm{x}_{N+1}$ is added, and the variable in the whole question becomes a collection of $N+1$ keyframes and more landmark points. This is actually still trivial, we just need to follow the normal BA process. When all points are marginalized, the Gaussian distribution parameters of the $N+1$ keyframes are obtained.

\subsubsection{Delete an old keyframe}
A theoretical issue will emerge when considering the removal of old keyframes. Let's say we want to delete the old keyframe $\bm{x}_1$, but $\bm{x}_1$ is not isolated, it will observe the same road signs as other frames. Edged $\bm{x}_1$ will cause the entire issue to be no longer sparse. As in the previous lecture, let's take a diagram, as shown by \autoref{fig:marg-frame}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{backend2/marg-frame.pdf}
    \caption{Sliding window to delete keyframes will destroy the diagonal block structure of the signpost section}
    \label{fig:marg-frame}
\end{figure}

In this example, we assume that $\bm{x}_1$ sees the landmarks $\bm{y}_1$ to $\bm{y}_4$, so before processing, the Hessian matrix of the BA problem should look like Like the left side of the diagram, the $\bm{y}_1$ to $\bm{y}_4$ column in the $\bm{x}_1$ line has a non-zero block representing $\bm{x}_1 $ saw them. Considering the marginalization of $\bm{x}_1$, then the Schur elimination process is equivalent to eliminating several non-zero matrix blocks at the non-diagonal line by matrix row and column operations, which obviously leads to the landmark point matrix in the lower right corner. Blocks are no longer non-diagonal matrices. This process is called \textbf{Fill-in}\textsuperscript{\cite{Sibley2008}} in marginalization.

Looking back at the marginalization of the previous lecture, when we point the way to the point, Fill-in will appear in the pose block in the upper left corner. However, because BA does not require the pose block to be a diagonal block, the sparse BA solution is still feasible. However, when the keyframe is marginalized, the diagonal block structure between the landmarks in the lower right corner will be destroyed, and the BA will not be iteratively solved according to the previous sparse mode. This is obviously a very bad problem. In fact, in the early EKF filter backend, people did maintain a dense Hessian matrix, which made the EKF backend unable to handle larger sliding windows.

However, if we make some modifications to the marginalization process, we can also maintain the sparseness of the sliding window BA. For example, when edged an old keyframe, it simultaneously marginalizes the landmark points it observes. In this way, the information of the landmark points is converted into the common view information between the remaining key frames, thereby maintaining the diagonal block structure of the lower right corner portion. In some SLAM frameworks \textsuperscript{\cite{Leutenegger2015, Engel2016}}, the marginalization strategy is more complicated. For example, in OKVIS, we will determine which keyframe to be marginalized, and whether the landmark points it sees can still be seen in the latest keyframes. If not, the marginal point is directly marginalized; if it is, then the observation of the landmark point by the marginal keyframe is discarded, thereby maintaining the sparsity of the BA.

\subsubsection{Intuitive interpretation of marginalization in SWF}
We know that the meaning of marginalization in probability refers to conditional probability. So intuitively, when we marginalize a keyframe, that is, "keep the current estimate of this keyframe and ask for the conditional probability that other state variables are conditional on this keyframe." Therefore, when a keyframe is marginalized, the landmark points it observes will produce a priori information of "\textbf{Where should these roadmaps be}, affecting the rest of the estimates. If these landmarks are marginalized, their observers will get a priori information about "\textbf{observe where their keyframes should be}.

Mathematically, when we marginalize a keyframe, the way the state variables are described in the entire window changes from a joint distribution to a conditional probability distribution. Looking at the above example, it means:
\begin{equation}
p\left( {{\bm{x}_1}, \ldots {\bm{x}_4},{\bm{y}_1}, \ldots {\bm{y}_6}} \right) = p\left( {{\bm{x}_2}, \ldots ,{\bm{x}_4},{\bm{y}_1}, \ldots {\bm{y}_6}|{\bm{x}_1}} \right)\underbrace {p\left( {{\bm{x}_1}} \right)}_{\text{舍去}}.
\end{equation}
Then the information of the marginalized part is discarded. After the variable is marginalized, we should not use it again in the project. Therefore, the sliding window method is more suitable for VO systems, and is not suitable for systems with large-scale mapping.

Since g2o and Ceres do not directly support the marginalization operation in the sliding window method. \footnote{We can bypass the g2o and Ceres framework restrictions by some clever means, but this is often very cumbersome and not suitable for the book. Demonstration. }, we skip the corresponding experimental part of this section. It is hoped that the theoretical part will help the reader understand some SLAM systems based on sliding windows.

\section{Pose Graph}
\subsection{The meaning of Pose Graph}
Based on the previous discussion, we found that feature points account for the vast majority of optimization problems. In fact, after several observations, those convergent feature points, the spatial position estimate will converge to a value that remains unchanged, while the divergent outer point is usually invisible. Optimizing the convergence point seems to be somewhat unrewarding. Therefore, we prefer to fix the feature points after several optimizations, and only regard them as constraints of pose estimation, and no longer actually optimize their position estimates.

Going down this line of thought, we will think: Can you completely ignore the road signs and just follow the track? We can construct a trajectory-only graph optimization, and the edges between the pose nodes can be given initial values ​​by motion estimation obtained after feature matching between two key frames. The difference is that once the initial estimate is complete, we no longer optimize the location of those landmarks, but only the connections between all camera poses. In this way, we save a lot of feature point optimization calculations, only retain the trajectory of key frames, thus constructing a so-called Pose Graph, such as \autoref{fig:pose-graph}~ Show.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{backend2/posegraph.pdf}
\caption{Pose Graph diagram. When we no longer optimize the landmark points in the Bundle Adjustment and only regard them as constraints on the pose nodes, we get a Pose Graph with a much smaller computational scale. }
\label{fig:pose-graph}
\end{figure}

We know that the number of feature points in the BA is much larger than the pose node. A keyframe is often associated with hundreds of key points, and the maximum computational scale of real-time BA, even with sparsity, is typically around tens of thousands of points on current mainstream CPUs. This limits the SLAM application scenario. Therefore, when the robot moves in a wider range of time and space, some solutions must be considered: either discard some historical data \textsuperscript{\cite{Strasdat2011}} like the sliding window method; or like Pose Graph , discard the optimization of the landmark points, only keep the edges between Pose, use Pose Graph\textsuperscript{\cite{Dubbelman2015, Lee2014, Latif2013}}. In addition, if we have additional sensors that measure Pose, then Pose Graph is also a common method of fused Pose measurements.


\subsection{Pose Graph Optimization}
So, what do the nodes and edges in the Pose Graph optimization mean? The node here represents the camera pose and is expressed as $\bm{T}_1, \cdots, \bm{T}_n$. The edge is an estimate of the relative motion between the two pose nodes. The estimate may come from the feature point method or the direct method, or it may come from GPS or IMU points, but in any case, we estimate, say $\bm A movement between {T}_i$ and $\bm{T}_j$ $\Delta \bm{T}_{ij}$. There are several ways to express this movement, and we take a more natural one:
\begin{equation}
\Delta \bm{\xi}_{ij} = \bm{\xi}_i^{-1} \circ \bm{\xi}_j = \ln \left( \bm{T}_i^{-1} \bm{T}_j \right)^\vee,
\end{equation}
Or by Li Qun's writing:
\begin{equation}
\bm{T}_{ij} =\bm{T}_i^{-1} \bm{T}_j.
\end{equation}

According to the idea of ​​graph optimization, the equation is not exactly established in practice, so we set the least squares error and then discuss the error about the derivative of the optimization variable as before. Here, we move the $\bm{T}_{ij}$ of the above formula to the right side of the equation, constructing the error $\bm{e}_{ij}$:
\begin{equation}
\bm{e}_{ij} = \Delta \bm{\xi}_{ij} \ln \left( \bm{T}_{ij}^{-1} \bm{T}_i^{-1} \bm{T}_j \right)^\vee
\end{equation}

Note that there are two optimization variables: $\bm{\xi}_i$ and $\bm{\xi}_j$, so we ask $\bm{e}_{ij}$ for the derivatives of these two variables. According to the Lie algebra's method of derivation, give $\bm{\xi}_i$ and $\bm{\xi}_j$ one left perturbation: $ \bm{\delta \xi}_i$ and $ \bm{\ Delta \xi}_j$. Then the error becomes
\begin{equation}
\hat{ \bm{e}}_{ij} = \ln \left( \bm{T}_{ij}^{-1}  \bm{T}_i^{-1} \exp((-\bm{\delta \xi}_i)^\wedge) \exp(\delta \bm{\xi}_j^\wedge) \bm{T}_j  \right)^\vee.
\end{equation}

In this equation, two disturbance terms are sandwiched. In order to take advantage of the BCH approximation, we want to move the perturbation term to the left or right side of the expression. Recall the adjoint nature of the fourth exercise, namely the formula \eqref{eq:adjSE3}. If you have not done this exercise, then use it as a correct conclusion for the time being:
\begin{equation}
\exp \left( \left( \mathrm{Ad}(\bm{T}) \bm{\xi} \right) ^\wedge \right) = \bm{T} \exp(\bm{\xi}^\wedge)\bm{T}^{-1}.
\end{equation}

A little change, there are:
\begin{equation}
\exp(\bm{\xi}^\wedge)\bm{T} = \bm{T} \exp \left( \left( \mathrm{Ad}(\bm{T}^{-1}) \bm{\xi} \right) ^\wedge \right) .
\end{equation}

This formula shows that by introducing a companion item, we can "swap" $\bm{T}$ on the left and right sides of the perturbation item. With it, you can move the disturbance to the far right (of course, the leftmost is also possible), and derive the Jacobian matrix of the right multiplication form (left multiplication when moving to the left):
\begin{equation}
\begin{aligned}
\hat{ \bm{e}}_{ij} &= \ln \left( \bm{T}_{ij}^{-1}  \bm{T}_i^{-1} \exp((-\bm{\delta \xi}_i)^\wedge) \exp(\delta \bm{\xi}_j^\wedge) \bm{T}_j  \right)^\vee\\
&= \ln \left( \bm{T}_{ij}^{-1} \bm{T}_i^{-1} \bm{T}_j \exp \left( \left(- \mathrm{Ad}(\bm{T}_j^{-1}) \bm{\delta \xi}_i \right)^\wedge \right) \exp \left( \left( \mathrm{Ad}(\bm{T}_j^{-1})  \bm{\delta\xi}_j\right)^\wedge \right) \right)^\vee \\ 
&\approx \ln \left( \bm{T}_{ij}^{-1} \bm{T}_i^{-1} \bm{T}_j \left[ \bm{I} - (\mathrm{Ad}(\bm{T}_j^{-1}) \bm{\delta \xi}_i)^\wedge + (\mathrm{Ad}(\bm{T}_j^{-1})  \bm{\delta \xi}_j)^{\wedge} \right] \right)^\vee \\
& \approx \bm{e}_{ij} + \frac{\partial \bm{e}_{ij}}{\partial \bm{\delta \xi}_i} \bm{\delta \xi}_i + \frac{\partial \bm{e}_{ij}}{\partial \bm{\delta \xi}_j} \bm{\delta \xi}_j
\end{aligned}.
\end{equation}

Therefore, according to the derivation rule on Lie algebra, we find the Jacobian matrix of the error about the two poses. About $\bm{T}_i$:
\begin{equation}
\frac{\partial \bm{e}_{ij}}{\partial \bm{\delta \xi}_i} = - \bm{\mathcal{J}}_r^{-1}(\bm{e}_{ij}) \mathrm{Ad}(\bm{T}_j^{-1}).
\end{equation}
And about $\bm{T}_j$:
\begin{equation}
\frac{\partial \bm{e}_{ij}}{\partial \bm{\delta \xi}_j} = \bm{\mathcal{J}}_r^{-1}(\bm{e}_{ij}) \mathrm{Ad}(\bm{T}_j^{-1}).
\end{equation}

If the reader feels that this part of the guide is difficult to understand, you can go back to the fourth part to review the contents of the Lie algebra. However, as I said before, since the left and right Jacobs on $\mathfrak{se}(3)$ are too complicated for $\bm{\mathcal{J}}_r$, we usually take their approximation. If the error is close to zero, we can set them to approximate $\bm{I}$ or
\begin{equation}
\bm{\mathcal{J}}_r^{-1}(\bm{e}_{ij}) \approx \bm{I} + \frac{1}{2} 
\left[ 
{\begin{array}{*{20}{c}}
	{{\bm{\phi}_{\bm{e}} ^ \wedge }}&{{\bm{\rho}_{\bm{e}} ^ \wedge }}\\
	{\bm{0}}&{{\bm{\phi}_{\bm{e}} ^ \wedge }}
\end{array}} 
\right].
\end{equation}

In theory, even after optimization, because the observation data given by each edge is not consistent, the error is usually not similar to zero, so simply set $\bm{\mathcal{J}}_r$ here to $\bm{I}$ will have a certain loss. Later we will see through practice whether the theoretical difference is obvious.

After learning about Jacobi's derivation, the rest is the same as the normal graph optimization. In short, all pose vertices and poses - poses constitute a graph optimization, essentially a least squares problem, the optimization variable is the pose of each vertex, and the edges are derived from pose observation constraints. Remember that $\mathcal{E}$ is a collection of all edges, then the overall objective function is
\begin{equation}
\mathop {\min }\limits \frac{1}{2}\sum\limits_{i,j \in \mathcal{E}} \bm{e}_{ij}^\mathrm{T} \bm{\Sigma}_{ij}^{-1} \bm{e}_{ij}.
\end{equation}

We can still solve this problem by Gauss-Newton method, Levinburg-Marquart method, etc., except that Lie algebra is used to represent the optimized pose, everything else is similar. Based on previous experience, this can naturally be solved with Ceres or g2o. We are no longer discussing the detailed process of optimization. The last lecture has already been said enough.

\section{Practice: Pose Optimization}
\subsection{g2o native pose}
The following demonstrates the use of g2o for pose optimization. First, the reader is asked to open our pre-generated simulation pose with g2o\_viewer, located in slambook2/ch10/sphere.g2o, as shown in \autoref{fig:sphere-before}~.

\begin{figure}[!htp]
\centering
\includegraphics[width=1.0\textwidth]{backend2/sphere-before.pdf}
\caption{g2o The pose map generated by the simulation. The true value is a complete sphere, and the simulation data with cumulative error is obtained by adding noise to the true value. }
\label{fig:sphere-before}
\end{figure}

The pose is generated by g2o's own create sphere program simulation. Its true trajectory is a ball, consisting of multiple layers from bottom to top. Each layer is a perfect circle, and many circular layers of different sizes form a complete sphere, which contains 2500 pose nodes (\autoref{fig:sphere-before}~top left), which can be seen as a circle. The process of ascending. The emulator then generates the edge of $t-1$ to $t$, called the odometry edge (odometer). In addition, the edge between the layer and the layer is generated, which is called loop closure (loopback, loopback detection algorithm will be described in detail in the next lecture). Then, add observation noise on each side and reset the initial value of the node based on the noise of the odometer side. In this way, the pose data with cumulative error (\autoref{fig:sphere-before}~bottom right) is obtained. It looks like a part of the sphere, but the overall shape is far from the sphere. Now we start from these noisy edges and node initial values, try to optimize the entire pose map to get the data of approximate truth value.

Of course, the actual robot will certainly not have such a spherical motion trajectory, and such complete odometer and loop observation data. The advantage of simulating a positive sphere is that we can visually see if the optimization result is correct (just look at it and the angles are not round). The reader can click on the optimize function in g2o\_viewer to see the optimization results and the convergence process for each step. On the other hand, sphere.g2o is also a text file that can be opened with a text editor to see what is inside it. The first half of the file consists of nodes, and the second half is edges:

\begin{lstlisting}
VERTEX_SE3:QUAT 0 -0.125664 -1.53894e-17 99.9999 0.706662 4.32706e-17 0.707551 -4.3325e-17 
......
EDGE_SE3:QUAT 1524 1574 -0.210399 -0.0101193 -6.28806 -0.00122939 0.0375067 -2.85291e-05 0.999296 10000 0 0 0 0 0 10000 0 0 0 0 10000 0 0 0 40000 0 0 40000 0 40000 
\end{lstlisting}

As you can see, the node type is VERTEX\_SE3, which expresses a camera pose. By default, g2o uses quaternions and translation vectors to express poses, so the following fields mean: ID, $t_x, t_y, t_z, q_x, q_y, q_z, q_w$. The first three are translation vector elements, and the last four are unit quaternions representing rotation. Similarly, the information of the edge is the ID of two nodes, $t_x, t_y, t_z, q_x, q_y, q_z, q_w$, the upper right corner of the information matrix (since the information matrix is ​​a symmetric matrix, only half of it can be saved). It can be seen that the information matrix is ​​set to a diagonal matrix.

To optimize this pose, we can use g2o's default vertices and edges, which are represented by quaternions. Since the simulation data is also generated by g2o, optimization with g2o itself does not require us to do more work, just configure the optimization parameters. The program slambook2/ch10/pose\_graph\_g2o\_SE3.cpp demonstrates how to optimize the pose using the Levenberg-Marquart method and store the result in the result.g2o file.

\begin{lstlisting}[language=c++,caption=slambook2/ch10/pose\_graph\_g2o\_SE3.cpp]
#include <iostream>
#include <fstream>
#include <string>

#include <g2o/types/slam3d/types_slam3d.h>
#include <g2o/core/block_solver.h>
#include <g2o/core/optimization_algorithm_levenberg.h>
#include <g2o/solvers/eigen/linear_solver_eigen.h>

using namespace std;

/************************************************
* This program demonstrates how to optimize poses with g2o solver
* sphere.g2o is a manually generated Pose graph, let's optimize it.
* Although we can read the entire graph directly through the load function, we still implement the read code ourselves in order to gain a deeper understanding.
* Here is the pose using SE3 in g2o/types/slam3d/, which is essentially a quaternion instead of a Lie algebra.
* **********************************************/

int main(int argc, char **argv) {
    if (argc != 2) {
        cout << "Usage: pose_graph_g2o_SE3 sphere.g2o" << endl;
        return 1;
    }
    ifstream fin(argv[1]);
    if (!fin) {
        cout << "file " << argv[1] << " does not exist." << endl;
        return 1;
    }
    
    // 设定g2o
    typedef g2o::BlockSolver<g2o::BlockSolverTraits<6, 6>> BlockSolverType;
    typedef g2o::LinearSolverEigen<BlockSolverType::PoseMatrixType> LinearSolverType;
    auto solver = new g2o::OptimizationAlgorithmLevenberg(
    g2o::make_unique<BlockSolverType>(g2o::make_unique<LinearSolverType>()));
    g2o::SparseOptimizer optimizer;     // 图模型
    optimizer.setAlgorithm(solver);   // 设置求解器
    optimizer.setVerbose(true);       // 打开调试输出
    
    int vertexCnt = 0, edgeCnt = 0; // 顶点和边的数量
    while (!fin.eof()) {
        string name;
        fin >> name;
        if (name == "VERTEX_SE3:QUAT") {
            // SE3 顶点
            g2o::VertexSE3 *v = new g2o::VertexSE3();
            int index = 0;
            fin >> index;
            v->setId(index);
            v->read(fin);
            optimizer.addVertex(v);
            vertexCnt++;
            if (index == 0)
            v->setFixed(true);
        } else if (name == "EDGE_SE3:QUAT") {
            // SE3-SE3 边
            g2o::EdgeSE3 *e = new g2o::EdgeSE3();
            int idx1, idx2;     // 关联的两个顶点
            fin >> idx1 >> idx2;
            e->setId(edgeCnt++);
            e->setVertex(0, optimizer.vertices()[idx1]);
            e->setVertex(1, optimizer.vertices()[idx2]);
            e->read(fin);
            optimizer.addEdge(e);
        }
        if (!fin.good()) break;
    }
    
    cout << "read total " << vertexCnt << " vertices, " << edgeCnt << " edges." << endl;
    
    cout << "optimizing ..." << endl;
    optimizer.initializeOptimization();
    optimizer.optimize(30);
    
    cout << "saving optimization results ..." << endl;
    optimizer.save("result.g2o");
    
    return 0;
}
\end{lstlisting}

We chose the block solver for $6\times6$, using the Levinberg-Marquart drop method, and selecting the number of iterations 30 times. Call this program to optimize the pose map:
\begin{lstlisting}[language=sh, caption=terminal input:]
$ build/pose_graph_g2o_SE3 sphere.g2o
Read total 2500 vertices, 9799 edges.
Optimizing ...
Iteration= 0 chi2= 1023011093.851879 edges= 9799 schur= 0 lambda= 805.622433 levenbergIter= 1
Iteration= 1 chi2= 385118688.233188 time= 0.863567 cumTime= 1.71545 edges= 9799 schur= 0 lambda= 537.081622 levenbergIter= 1
Iteration= 2 chi2= 166223726.693659 time= 0.861235 cumTime= 2.57668 edges= 9799 schur= 0 lambda= 358.054415 levenbergIter= 1
Iteration= 3 chi2= 86610874.269316 time= 0.844105 cumTime= 3.42079 edges= 9799 schur= 0 lambda= 238.702943 levenbergIter= 1
Iteration= 4 chi2= 40582782.710190 time= 0.862221 cumTime= 4.28301 edges= 9799 schur= 0 lambda= 159.135295 levenbergIter= 1
......
Iteration= 28 chi2= 45095.174398 time= 0.869451 cumTime= 30.0809 edges= 9799 schur= 0 lambda= 0.003127 levenbergIter= 1
Iteration= 29 chi2= 44811.248504 time= 1.76326 cumTime= 31.8442 edges= 9799 schur= 0 lambda= 0.003785 levenbergIter= 2
Saving optimization results ...
\end{lstlisting}

Then, open the result.g2o with g2o\_viewer to see the results, as shown by \autoref{fig:result-SE3}~.
\begin{figure}[!ht]
\centering
\includegraphics[width=0.75\textwidth]{backend2/result-SE3.pdf}
\caption{Use the result of the vertex and edge solution that comes with g2o. }
\label{fig:result-SE3}
\end{figure}

The result is optimized from an irregular shape into a seemingly complete ball. This process is essentially the same as the one we clicked on the Optimize button on g2o\_viewer. Below, we use the previous Lie algebra to derive the optimization on the Lie algebra.

\subsection{Pose map optimization on Lie algebra}
Remember when we used Sophus to express Lie algebra? Let's try to use Sophus to define its own vertices and edges in g2o.

\clearpage
\begin{lstlisting}[language=c++,caption=slambook2/ch10/pose\_graph\_g2o\_lie\_algebra.cpp（片段）]
typedef Matrix<double, 6, 6> Matrix6d;

// Approximate error for J_R^{-1}
Matrix6d JRInv(const SE3d &e) {
    Matrix6d J;
    J.block(0, 0, 3, 3) = SO3d::hat(e.so3().log());
    J.block(0, 3, 3, 3) = SO3d::hat(e.translation());
    J.block(3, 0, 3, 3) = Matrix3d::Zero(3, 3);
    J.block(3, 3, 3, 3) = SO3d::hat(e.so3().log());
    J = J * 0.5 + Matrix6d::Identity();
    return J;
}

// Lie algebra vertices
Typedef Matrix<double, 6, 1> Vector6d;

class VertexSE3LieAlgebra : public g2o::BaseVertex<6, SE3d> {
    public:
    EIGEN_MAKE_ALIGNED_OPERATOR_NEW
    
    virtual bool read(istream &is) override {
        double data[7];
        for (int i = 0; i < 7; i++)
        is >> data[i];
        setEstimate(SE3d(
        Quaterniond(data[6], data[3], data[4], data[5]),
        Vector3d(data[0], data[1], data[2])
        ));
    }
    
    virtual bool write(ostream &os) const override {
        os << id() << " ";
        Quaterniond q = _estimate.unit_quaternion();
        os << _estimate.translation().transpose() << " ";
        os << q.coeffs()[0] << " " << q.coeffs()[1] << " " << q.coeffs()[2] << " " << q.coeffs()[3] << endl;
        return true;
    }
    
    virtual void setToOriginImpl() override {
        _estimate = SE3d();
    }
    
    // left multiply update
    Virtual void oplusImpl(const double *update) override {
        Vector6d upd;
        upd << update[0], update[1], update[2], update[3], update[4], update[5];
        _estimate = SE3d::exp(upd) * _estimate;
    }
};

// sides of two Lie algebra nodes
Class EdgeSE3LieAlgebra : public g2o::BaseBinaryEdge<6, SE3d, VertexSE3LieAlgebra, VertexSE3LieAlgebra> {
    Public:
    EIGEN_MAKE_ALIGNED_OPERATOR_NEW
    
    virtual bool read(istream &is) override {
        double data[7];
        for (int i = 0; i < 7; i++)
        is >> data[i];
        Quaterniond q(data[6], data[3], data[4], data[5]);
        q.normalize();
        setMeasurement(SE3d(q, Vector3d(data[0], data[1], data[2])));
        for (int i = 0; i < information().rows() && is.good(); i++)
        for (int j = i; j < information().cols() && is.good(); j++) {
            is >> information()(i, j);
            if (i != j)
            information()(j, i) = information()(i, j);
        }
        return true;
    }
    
    virtual bool write(ostream &os) const override {
        VertexSE3LieAlgebra *v1 = static_cast<VertexSE3LieAlgebra *> (_vertices[0]);
        VertexSE3LieAlgebra *v2 = static_cast<VertexSE3LieAlgebra *> (_vertices[1]);
        os << v1->id() << " " << v2->id() << " ";
        SE3d m = _measurement;
        Eigen::Quaterniond q = m.unit_quaternion();
        os << m.translation().transpose() << " ";
        os << q.coeffs()[0] << " " << q.coeffs()[1] << " " << q.coeffs()[2] << " " << q.coeffs()[3] << " ";
        
        // information matrix 
        for (int i = 0; i < information().rows(); i++)
        for (int j = i; j < information().cols(); j++) {
            os << information()(i, j) << " ";
        }
        os << endl;
        return true;
    }
    
    // The error calculation is consistent with the derivation in the book
    Virtual void computeError() override {
        SE3d v1 = (static_cast<VertexSE3LieAlgebra *> (_vertices[0]))->estimate();
        SE3d v2 = (static_cast<VertexSE3LieAlgebra *> (_vertices[1]))->estimate();
        _error = (_measurement.inverse() * v1.inverse() * v2).log();
    }
    
    // Jacobi calculation
    Virtual void linearizeOplus() override {
        SE3d v1 = (static_cast<VertexSE3LieAlgebra *> (_vertices[0]))->estimate();
        SE3d v2 = (static_cast<VertexSE3LieAlgebra *> (_vertices[1]))->estimate();
        Matrix6d J = JRInv(SE3d::exp(_error));
        // Try to approximate J to I?
        _jacobianOplusXi = -J * v2.inverse().Adj();
        _jacobianOplusXj = J * v2.inverse().Adj();
    }
};
\end{lstlisting}


In order to store and read g2o files, this section implements the read and write functions and "disguises" into g2o's built-in SE3 vertices, enabling g2o\_viewer to recognize and render it. In fact, apart from the internal representation of Sophus's Lie algebra, there is no difference from the outside.

It is worth noting the calculation process of Jacobi here. We have several options: First, do not provide the Jacobian calculation function, let g2o automatically calculate the value of Jacobi. The second is to provide a complete or approximate Jacobian calculation process. Here we use the JRInv() function to provide an approximate $\bm{\mathcal{J}}_r^{-1}$. The reader can try to approximate it as $\bm{I}$, or simply comment out the oplusImpl function and see what the difference is.

Then call g2o to optimize the problem:

\begin{lstlisting}[language=sh,caption=terminal input:]
$ build/pose_graph_g2o_lie sphere.g2o
Read total 2500 vertices, 9799 edges.
Optimizing ...
Iteration= 0 chi2= 626657736.014949 time= 0.549125 cumTime= 0.549125 edges= 9799 schur= 0 lambda= 6706.585223 levenbergIter= 1
Iteration= 1 chi2= 233236853.521434 time= 0.510685 cumTime= 1.05981 edges= 9799 schur= 0 lambda= 2235.528408 levenbergIter= 1
Iteration= 2 chi2= 142629876.750105 time= 0.557893 cumTime= 1.6177 edges= 9799 schur= 0 lambda= 745.176136 levenbergIter= 1
Iteration= 3 chi2= 84218288.615592 time= 0.525079 cumTime= 2.14278 edges= 9799 schur= 0 lambda= 248.392045 levenbergIter= 1
......
\end{lstlisting}

We found that after 23 iterations, the overall error remains the same, in fact the optimization algorithm can be stopped. In the previous experiment, the error was still declining after using 30 iterations. Please note that although the numerical error here is larger, we have redefine the calculation of the error because we customize the edge.So the size of the value here is not directly used for comparison. After calling the optimization, look at result\_lie.g2o to see its results, as shown by \autoref{fig:result-lie}~. No difference can be seen from the naked eye.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.72\textwidth]{backend2/result-lie.pdf}
    \caption{Use Lie algebra to customize the result of node and edge optimization. }
    \label{fig:result-lie}
\end{figure}
    
If you press the Optimize button on this g2o\_viewer interface, g2o will use its own SE3 vertices for optimization, you can see in the text box below:
    
\begin{lstlisting}
Loaded result_lie.g2o with 2500 vertices and 9799 measurements
Graph is fixed by node 2499
# Using CHOLMOD poseDim -1 landMarkDim -1 blockordering 0
Preparing (no marginalization of Landmarks)
iteration= 0 chi2= 44360.509723 time= 0.567504 cumTime= 0.567504 edges= 9799 schur= 0
iteration= 1 chi2= 44360.471110 time= 0.595993 cumTime= 1.1635   edges= 9799 schur= 0
iteration= 2 chi2= 44360.471110 time= 0.582909 cumTime= 1.74641  edges= 9799 schur= 0
\end{lstlisting}
    
    The overall error is 44360 at the SE3 side, slightly less than the 44811 at the previous 30 iterations. This shows that after optimizing with Lie algebra, we get better results with fewer iterations\footnote{ Since there are no more experiments, this conclusion is only valid in the example of "ball". }. In fact, even if we use the unit matrix to approximate $\bm{\mathcal{J}}_r^{-1}$, you will converge to a similar value. This is mainly because when the error is close to zero, Jacobi is very close to the identity matrix.
    
\subsection{小结}
The example of the ball is a more representative case. It has an Odometry and a Loop Closure similar to the actual one, which is what is possible in a pose in the actual SLAM. At the same time, the "ball" also has a certain scale of calculation: it has a total of 2,500 pose nodes and nearly 10,000 edges, and we found that it took a lot of time to optimize it (relative to the front end with strong real-time requirements). On the other hand, the pose map is generally considered to be one of the simplest structures. Under the premise of not assuming how the robot moves, it is difficult to further discuss its sparsity - because the robot may move straight forward, forming a band-like pose, which is sparse; it may also be "left-handed and right-handed A slow motion", the formation of a large number of small loops requires optimization (Loopy motion), which becomes a more dense pose of the "ball". In any case, before we have any further information, we can no longer use the solution structure of the pose map.

Since the introduction of PTAM\textsuperscript{\cite{Klein2007}}, people have realized that the optimization of the backend does not need to respond to the image data of the front end in real time. People tend to separate the front end and the back end, running in two separate threads, historically called Tracking and Mapping - although so, the mapping part mainly refers to the back-end optimization content. In layman's terms, the front end needs to respond to the video in real time, for example 30 frames per second; and optimization can be run slowly, as long as the results are returned to the front end when optimization is complete. So we usually don't put high speed requirements on backend optimization.

    
    
\section*{ Exercises}
    \begin{enumerate}
        \item If the error in the pose is defined as $\Delta \bm{\xi}_{ij} = \bm{\xi}_i \circ \bm{\xi}_j^{-1}$, derivation The left-multiplying Jacobian matrix according to this definition.
        \item If you use a right multiply update, derive the Jacobian matrix in this case.
        \item Refer to the g2o program to optimize the "ball" pose in Ceres.
        \item sorts the information in the "ball" by time, feeds them to g2o and gtsam, and compares their performance differences.
        \item[\optional] Read the iSAM related paper and understand how it implements incremental optimization.
    \end{enumerate}
